{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sBEtedtFZ8N"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets,transforms \n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler \n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6bdwZM5FcXH"
      },
      "source": [
        "with zipfile.ZipFile(\"face_data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"./\")\n",
        "with zipfile.ZipFile(\"face_test.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"./\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m6_E2XMGV5_"
      },
      "source": [
        "mean_arr = [0.485, 0.456, 0.406]\n",
        "std_arr = [0.229, 0.224, 0.225]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-wmiSITGZ4T"
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean,\n",
        "                         std=std)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ml98o-UGdlp"
      },
      "source": [
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean,\n",
        "                         std=std)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5tVOXlUGiIE"
      },
      "source": [
        "train_path = 'face_data/train/'\n",
        "test_path = 'face_data/val/'\n",
        "\n",
        "train_data = datasets.ImageFolder(root=train_path,\n",
        "                                  transform=train_transform)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=4,\n",
        "                                           shuffle=True, num_workers=4)\n",
        "\n",
        "test_data = datasets.ImageFolder(root=test_path,\n",
        "                                transform=test_transform)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=8,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "\n",
        "data_loader_dict = {\n",
        "    'train': train_data_loader,\n",
        "    'test': test_data_loader\n",
        "}\n",
        "\n",
        "class_names = train_data.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHdYa_EJGivl"
      },
      "source": [
        "def imshow(input, title):\n",
        "    input = input.cpu().numpy().transpose((1, 2, 0))\n",
        "    input = std * input + mean\n",
        "    input = np.clip(input, 0, 1)\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(input)\n",
        "    plt.title(title)\n",
        "    plt.pause(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AkpVu65G1qg"
      },
      "source": [
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "output = torchvision.utils.make_grid(inputs)\n",
        "imshow(output, title=[class_names[x] for x in classes])\n",
        "\n",
        "model = models.alexnet(pretrained=True)\n",
        "num_of_features = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_of_features, len(class_names))\n",
        "entropy_loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "dataset_length_dict = {\n",
        "    'train': len(train_data),\n",
        "    'test': len(test_data)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0uDDXPjG38w"
      },
      "source": [
        "def train_model(model, loss, optimizer, num_of_epochs=500):\n",
        "    c_time = time.time()\n",
        "    loss_arr = list()\n",
        "    best_model = copy.deepcopy(model.state_dict())\n",
        "    best_accuracy = 0.0\n",
        "    for epoch in range(num_of_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_of_epochs))\n",
        "        for stage in ['train', 'test']:\n",
        "            if stage == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            current_loss = 0.0\n",
        "            current_acc = 0\n",
        "            for inputs, labels in dataloaders[stage]:\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(stage == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, predictions = torch.max(outputs, 1)\n",
        "                    loss = loss(outputs, labels)\n",
        "                    if stage == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                \n",
        "                loss_arr.append(loss.item())\n",
        "                current_loss += loss.item() * inputs.size(0)\n",
        "                current_acc += torch.sum(predictions == labels.data)\n",
        "            epoch_loss = current_loss / dataset_length_dict[stage]\n",
        "            epoch_acc = current_acc.double()/dataset_length_dict[stage]\n",
        "\n",
        "            if stage == 'test' and epoch_acc > best_model:\n",
        "                best_model = epoch_acc\n",
        "                best_model = copy.deepcopy(model.state_dict())\n",
        "    print('Best accuracy: {:4f}'.format(best_model))\n",
        "    model.load_state_dict(best_model)\n",
        "    return model, loss_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYjxPI9yG7OS"
      },
      "source": [
        "model, loss_arr = train_model(model, entropy_loss, optimizer, num_of_epochs=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqtBNY-FG-Ic"
      },
      "source": [
        "with torch.no_grad():\n",
        "    acc = 0\n",
        "    total = 0\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean,\n",
        "                             std=std)\n",
        "    ])\n",
        "    path = \"face_data/val/\"\n",
        "\n",
        "    test_data = datasets.ImageFolder(root=path,\n",
        "                                transform=test_transform)\n",
        "\n",
        "    test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=8,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "\n",
        "    for images, labels in test_data_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        acc += (predicted == labels).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxOb9OCtHAoa"
      },
      "source": [
        "torch.save(model, './model_final')\n",
        "file_name = './model_final'\n",
        "s3 = boto3.resource('s3')\n",
        "bucket = 'attendance-model'\n",
        "s3.meta.client.upload_file(file_name, bucket, 'model_final')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}